---
title: "Untitled"
author: "Andrea Quets"
date: "4/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
```

```{r}
#policy for player
ACTION_HIT = 0
ACTION_STAND = 1  
actions = list(ACTION_HIT, ACTION_STAND)


policy_player = rep(0,22)
for (i in range(12,20)){ #is this diff because python has a stupid thing with zeros
  policy_player[i] = ACTION_HIT
}

policy_player[20]= ACTION_STAND
policy_player[21]= ACTION_STAND
```

```{r}
#"function form of target policy of player"
targetPolicyPlayer = function(usableAcePlayer, playerSum, dealerCard) {
  return(policy_player[playerSum])
}


#function form of behavior policy of player
behaviorPolicyPlayer = function(usableAcePlayer, playerSum, dealerCard){
    if (sample(c(1, 0.5), 1) == 1){
        return(ACTION_STAND)
    }
    return(ACTION_HIT)
}



    
```

```{r}
#policy for dealer

policy_dealer = rep(0,22)
for (i in range(12,17)){
  policy_dealer[i]= ACTION_HIT
}
for (i in range(17,22)){
  policy_dealer[i] = ACTION_STAND
  
}
```

```{r}
#get a new card

get_card = function(){
  card = sample(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14),1)
  card = min(card, 10)
  return(card)
}


```


```{r}

# play a game

play = function(policyPlayerFn, initialState=NA, initialAction=NA) {
    # player status

    # sum of player
    playerSum = 0

    # trajectory of player
    playerTrajectory = NULL

    # whether player uses Ace as 11
    usableAcePlayer = F

    # dealer status
    dealerCard1 = 0
    dealerCard2 = 0
    usableAceDealer = F

    if (is.na(initialState)){
        # generate a random initial state

        numOfAce = 0

        # initialize cards of player
        while (playerSum < 12){
            # if sum of player is less than 12, always hit
            card = getCard()

            # if get an Ace, use it as 11
            if (card == 1){
                numOfAce = numOfAce + 1
                card = 11
                usableAcePlayer = True
            playerSum = playerSum + card
            }
        }

        # if player's sum is larger than 21, he must hold at least one Ace, two Aces are possible
        if (playerSum > 21){
            # use the Ace as 1 rather than 11
            playerSum = playerSum - 10

            # if the player only has one Ace, then he doesn't have usable Ace any more
            if (numOfAce == 1) {
                usableAcePlayer = F
            }
        }

        # initialize cards of dealer, suppose dealer will show the first card he gets
        dealerCard1 = getCard()
        dealerCard2 = getCard()
    }   else {
          # use specified initial state
          usableAcePlayer = initialState[0]
          playerSum = initialState[1]
          dealerCard1 = initialState[2]
          dealerCard2 = getCard()
        }
    
    # initial state of the game
    state = list(usableAcePlayer, playerSum, dealerCard1)

    # initialize dealer's sum
    dealerSum = 0
    if (dealerCard1 == 1 & dealerCard2 != 1){
        dealerSum = dealerSum + 11 + dealerCard2
        usableAceDealer = T
    }
    if (dealerCard1 != 1 & dealerCard2 == 1){
        dealerSum  = dealerSUm + dealerCard1 + 11
        usableAceDealer = T
    }
    
    if (dealerCard1 == 1 & dealerCard2 == 1){
        dealerSum  = dealerSum + 1 + 11
        usableAceDealer = T
    }  
    else{
        dealerSum  = dealerSum + dealerCard1 + dealerCard2
    }
    # game starts!

    # player's turn
    while (T) {
        if (is.na(initialAction) != T) {
            action = initialAction
            initialAction = NA
        }
        else{
            # get action based on current sum
            action = policyPlayerFn(usableAcePlayer, playerSum, dealerCard1)
        }

        # track player's trajectory for importance sampling
        playerTrajectory[[1]] = append(playerTrajectory, action)
         playerTrajectory[[2]] = append(playerTrajectory, list(usableAcePlayer, playerSum, dealerCard1))
        

        if (action == ACTION_STAND){
            break
        }
        # if hit, get new card
        playerSum = playerSum + getCard()

        # player busts
        if (playerSum > 21){
            # if player has a usable Ace, use it as 1 to avoid busting and continue
            if (usableAcePlayer == True){
                playerSum = playerSum - 10
                usableAcePlayer = F
            }
            else {
                # otherwise player loses
                return(state, -1, playerTrajectory)
            }
        }
    }

    # dealer's turn
    while (T) {
        # get action based on current sum
        action = policyDealer[dealerSum]
        if (action == ACTION_STAND) {
            break
        }
        # if hit, get a new card
        dealerSum = dealerSum + getCard()
        # dealer busts
        if (dealerSum > 21){
            if (usableAceDealer == True) {
            # if dealer has a usable Ace, use it as 1 to avoid busting and continue
                dealerSum = dealerSum - 10
                usableAceDealer = F
                
            }
            else {
            # otherwise dealer loses
                return(state, 1, playerTrajectory)
            }
        }
    }
    # compare the sum between player and dealer
    if (playerSum > dealerSum) {
        return(state, 1, playerTrajectory)
    } else {
      if (playerSum == dealerSum){
        return(state, 0, playerTrajectory)
      }else{
        return(state, -1, playerTrajectory)
      }
    }  
}
```

```{r}

# Monte Carlo Sample with On-Policy
monteCarloOnPolicy = function(nEpisodes) {
    statesUsableAce = matrix(0,10,10)
    # initialze counts to 1 to avoid 0 being divided
    statesUsableAceCount = matrix(1,10,10)
    statesNoUsableAce = matrix(0, 10, 10)
    # initialze counts to 1 to avoid 0 being divided
    statesNoUsableAceCount = matrix(1, 10, 10)
    for (i in range(0, nEpisodes)){
        #state, reward, _ = play(targetPolicyPlayer)
        state = play(targetPolicyPlayer)[1]
        reward = play(targetPolicyPlayer)[2]
        state[1] = state[1] -12
        state[2] = state[2]- 1
        if (state[0] > 0){
            statesUsableAceCount[state[1], state[2]]  = statesUsableAceCount[state[1], state[2]] + 1
            statesUsableAce[state[1], state[2]] = statesUsableAce[state[1], state[2]] + reward
        }
        else{
            statesNoUsableAceCount[state[1], state[2]] = statesNoUsableAceCount[state[1], state[2]] + 1
            statesNoUsableAce[state[1], state[2]] = statesNoUsableAceCount[state[1], state[2]]+ reward
        }
    }
    return(statesUsableAce / statesUsableAceCount, statesNoUsableAce / statesNoUsableAceCount)
}


# Monte Carlo with Exploring Starts
monteCarloES = function(nEpisodes){
    # (playerSum, dealerCard, usableAce, action)
    stateActionValues = rep(list(matrix(0, 2, 2)), 100) # this might be wrong way to translate
    # initialze counts to 1 to avoid division by 0
    stateActionPairCount = rep(list(matrix(1, 2, 2)), 100)

    # behavior policy is greedy
    behaviorPolicy = function(usableAce, playerSum, dealerCard){
        usableAce = as.numeric(usableAce)
        playerSum = playerSum - 12
        dealerCard = dealerCard - 1
        # get argmax of the average returns(s, a)
        return(np.argmax(stateActionValues[playerSum, dealerCard, usableAce] #not sure what's up with colon, just deleted it probaby come back to this
                      / stateActionPairCount[playerSum, dealerCard, usableAce])) #not sure what's up with colon, just deleted it probaby come back to this
    }
    # play for several episodes
    for (episode in range(nEpisodes)){
        if (episode % 1000 == 0){ 
        #The % symbol in Python is called the Modulo Operator. It returns the remainder of dividing the left hand operand by right hand operand. It's used to get the remainder of a division problem.
            print('episode:', episode)
        }
        # for each episode, use a randomly initialized state and action
        initialState = list(sample(c(0,2), 1, replace = T),
                       sample(c(12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22), 1, replace = T),
                       sample(c(1, 2, 3, 4, 5, 6,7, 8, 9, 10,11)))
        initialAction = sample(actions, 1, replace = T)
        reward = play(behaviorPolicy, initialState, initialAction)[2]
        trajectory = play(behaviorPolicy, initialState, initialAction)[3]
      
        for (action, (usableAce, playerSum, dealerCard) in trajectory) {
            usableAce = int(usableAce)
            playerSum = playerSum - 12
            dealerCard = dealerCard - 1
            # update values of state-action pairs
            stateActionValues[playerSum, dealerCard, usableAce, action] = stateActionValues[playerSum, dealerCard, usableAce, action] + reward
            stateActionPairCount[playerSum, dealerCard, usableAce, action] = stateActionPairCount[playerSum, dealerCard, usableAce, action]+ 1
        }
    }

    return(stateActionValues / stateActionPairCount)
}

```

```{r}

# print the state value
figureIndex = 0
def prettyPrint(data, tile, zlabel='reward'):
    global figureIndex
    fig = plt.figure(figureIndex)
    figureIndex += 1
    fig.suptitle(tile)
    ax = fig.add_subplot(111, projection='3d')
    x_axis = []
    y_axis = []
    z_axis = []
    for i in range(12, 22):
        for j in range(1, 11):
            x_axis.append(i)
            y_axis.append(j)
            z_axis.append(data[i - 12, j - 1])
    ax.scatter(x_axis, y_axis, z_axis,c='red')
    ax.set_xlabel('player sum')
    ax.set_ylabel('dealer showing')
    ax.set_zlabel(zlabel)



# On-Policy results
def onPolicy():
    statesUsableAce1, statesNoUsableAce1 = monteCarloOnPolicy(10000)
    statesUsableAce2, statesNoUsableAce2 = monteCarloOnPolicy(500000)
    prettyPrint(statesUsableAce1, 'Usable Ace & 10000 Episodes')
    prettyPrint(statesNoUsableAce1, 'No Usable Ace & 10000 Episodes')
    prettyPrint(statesUsableAce2, 'Usable Ace & 500000 Episodes')
    prettyPrint(statesNoUsableAce2, 'No Usable Ace & 500000 Episodes')
    plt.show()
    
    
# Optimized or Monte Calro Control 
def MC_ES_optimalPolicy():
    stateActionValues = monteCarloES(500000)
    stateValueUsableAce = np.zeros((10, 10))
    stateValueNoUsableAce = np.zeros((10, 10))
    # get the optimal policy
    actionUsableAce = np.zeros((10, 10), dtype='int')
    actionNoUsableAce = np.zeros((10, 10), dtype='int')
    for i in range(10):
        for j in range(10):
            stateValueNoUsableAce[i, j] = np.max(stateActionValues[i, j, 0, :])
            stateValueUsableAce[i, j] = np.max(stateActionValues[i, j, 1, :])
            actionNoUsableAce[i, j] = np.argmax(stateActionValues[i, j, 0, :])
            actionUsableAce[i, j] = np.argmax(stateActionValues[i, j, 1, :])
    prettyPrint(stateValueUsableAce, 'Optimal state value with usable Ace')
    prettyPrint(stateValueNoUsableAce, 'Optimal state value with no usable Ace')
    prettyPrint(actionUsableAce, 'Optimal policy with usable Ace', 'Action (0 Hit, 1 Stick)')
    prettyPrint(actionNoUsableAce, 'Optimal policy with no usable Ace', 'Action (0 Hit, 1 Stick)')
    plt.show()



# Run on policy function
onPolicy()

# Run Monte Carlo Control or Explored starts
MC_ES_optimalPolicy()


```

it's a flag which makes snese to think of a switch/ switch like so that you can turn off verbose or turn on verbose. if true would juust always be true. if a constant number it would be true if not zero. true things run in  if statements.
